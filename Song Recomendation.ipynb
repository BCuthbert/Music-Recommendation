{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "629645f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import h5py\n",
    "import tables\n",
    "import hdf5_getters\n",
    "import glob\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f0fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:/Users/brade/Downloads/millionsongsubset/MillionSongSubset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c392ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_data_from_file(file_path):\n",
    "    \"\"\" Extracts the required song data from a single HDF5 file. \"\"\"\n",
    "    try:\n",
    "        # Open the HDF5 file\n",
    "        h5_file = hdf5_getters.open_h5_file_read(file_path)\n",
    "        \n",
    "        # Extract the number of songs in the file\n",
    "        song_num = hdf5_getters.get_num_songs(h5_file)\n",
    "        \n",
    "        song_data_list = []  # List to store the data for all songs\n",
    "        \n",
    "        for i in range(song_num):\n",
    "            # Extract the required features for each song using the index\n",
    "            song_id = hdf5_getters.get_song_id(h5_file, i)\n",
    "            similar_artists = hdf5_getters.get_similar_artists(h5_file, i)\n",
    "            title = hdf5_getters.get_title(h5_file, i)\n",
    "            hotness = hdf5_getters.get_song_hotttnesss(h5_file, i)\n",
    "            duration = hdf5_getters.get_duration(h5_file, i)\n",
    "            tempo = hdf5_getters.get_tempo(h5_file, i)\n",
    "            track_id = hdf5_getters.get_track_id(h5_file, i)\n",
    "            artist = hdf5_getters.get_artist_id(h5_file, i)\n",
    "            \n",
    "            # Append the extracted data for the current song to the list\n",
    "            song_data = {\n",
    "                'song_id': song_id,\n",
    "                'similar_artists': similar_artists,\n",
    "                'title': title,\n",
    "                'hotness': hotness,\n",
    "                'duration': duration,\n",
    "                'tempo': tempo,\n",
    "                'track_id': track_id,\n",
    "                'artist': artist\n",
    "            }\n",
    "            song_data_list.append(song_data)\n",
    "        \n",
    "        # Close the file after extraction\n",
    "        h5_file.close()\n",
    "        \n",
    "        # Return the list of song data dictionaries\n",
    "        return song_data_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "def get_all_files(basedir,ext='.h5') :\n",
    "    \"\"\"\n",
    "    From a root directory, go through all subdirectories\n",
    "    and find all files with the given extension.\n",
    "    Return all absolute paths in a list.\n",
    "    \"\"\"\n",
    "    allfiles = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files :\n",
    "            allfiles.append( os.path.abspath(f) )\n",
    "    return allfiles\n",
    "\n",
    "def construct_dataframe_from_directory(directory):\n",
    "    \"\"\" Construct a DataFrame by iterating through all the HDF5 files in the given directory. \"\"\"\n",
    "    song_data = []\n",
    "    \n",
    "    songs = get_all_files(directory)  # Get the list of songs in the directory\n",
    "    \n",
    "    for song in songs:\n",
    "        song_data_from_file = get_song_data_from_file(song)\n",
    "        \n",
    "        if song_data_from_file:\n",
    "            # Flatten the list of song data into the main list\n",
    "            song_data.extend(song_data_from_file)\n",
    "    \n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(song_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "913094d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 song_id                                    similar_artists  \\\n",
      "0  b'SOMZWCG12A8C13C480'  [b'ARV4KO21187FB38008', b'ARWHM281187FB3D381',...   \n",
      "1  b'SOCIWDW12A8C13D406'  [b'ARSZWK21187B9B26D7', b'ARLDW2Y1187B9B544F',...   \n",
      "2  b'SOXVLOJ12AB0189215'  [b'ARFSJUG11C8A421AAD', b'AR8SD041187FB36015',...   \n",
      "3  b'SONHOTT12A8C13493C'  [b'AR4R0741187FB39AF2', b'AR0D7K21187B9AD14E',...   \n",
      "4  b'SOFSOCN12A8C143F5D'  [b'ARUA62A1187B99D9B0', b'ARHJFFY1187B98BA76',...   \n",
      "\n",
      "                 title   hotness   duration    tempo               track_id  \\\n",
      "0  b\"I Didn't Mean To\"  0.602120  218.93179   92.198  b'TRAAAAW128F429D538'   \n",
      "1         b'Soul Deep'       NaN  148.03546  121.274  b'TRAAABD128F429CF47'   \n",
      "2   b'Amor De Cabaret'       NaN  177.47546  100.070  b'TRAAADZ128F9348C2E'   \n",
      "3   b'Something Girls'       NaN  233.40363  119.293  b'TRAAAEF128F4273421'   \n",
      "4    b'Face the Ashes'  0.604501  209.60608  129.738  b'TRAAAFD128F92F423A'   \n",
      "\n",
      "                  artist  \n",
      "0  b'ARD7TVE1187B99BFB1'  \n",
      "1  b'ARMJAGH1187FB546F3'  \n",
      "2  b'ARKRRTF1187B9984DA'  \n",
      "3  b'AR7G5I41187FB4CE6C'  \n",
      "4  b'ARXR32B1187FB57099'  \n"
     ]
    }
   ],
   "source": [
    "d = construct_dataframe_from_directory(base_path)\n",
    "print(d.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a4207a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def construct_graph_from_dataframe(df, min_songs_per_artist=2):\n",
    "    \"\"\" Construct a graph from the song data stored in a DataFrame, with a threshold for connections. \"\"\"\n",
    "    graph = defaultdict(set)  # Each song will have a set of connected songs\n",
    "    \n",
    "    # Iterate through each song in the dataframe\n",
    "    for _, row in df.iterrows():\n",
    "        song_id = row['song_id']\n",
    "        artist_id = row['artist']\n",
    "        \n",
    "        # Find other songs by the same artist\n",
    "        same_artist_songs = df[df['artist'] == artist_id]\n",
    "        \n",
    "        # Only create edges if there are at least 'min_songs_per_artist' songs by the same artist\n",
    "        if len(same_artist_songs) >= min_songs_per_artist:\n",
    "            for _, other_row in same_artist_songs.iterrows():\n",
    "                other_song_id = other_row['song_id']\n",
    "                \n",
    "                # Avoid connecting a song to itself\n",
    "                if song_id != other_song_id:\n",
    "                    graph[song_id].add(other_song_id)\n",
    "                    graph[other_song_id].add(song_id)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "763d36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = construct_graph_from_dataframe(d, min_songs_per_artist=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "247788ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamic_adar_similarity(song_id_1, song_id_2, graph):\n",
    "    common_neighbors = graph.get(song_id_1, set()).intersection(graph.get(song_id_2, set()))\n",
    "    \n",
    "    if not common_neighbors:\n",
    "        return 0\n",
    "    \n",
    "    score = 0\n",
    "    for neighbor in common_neighbors:\n",
    "        if neighbor in graph:\n",
    "            degree = len(graph[neighbor])\n",
    "            if degree > 1:\n",
    "                score += 1 / math.log(degree)\n",
    "    return score\n",
    "\n",
    "# Step 3: Generate recommendations for a user based on liked songs\n",
    "MIN_SIMILARITY_SCORE = 0.1\n",
    "\n",
    "def recommend_songs(user_liked_songs, graph, top_n=5, min_similarity=MIN_SIMILARITY_SCORE):\n",
    "    similarity_scores = defaultdict(float)\n",
    "    \n",
    "    for liked_song in user_liked_songs:\n",
    "        for other_song in list(graph.keys()):\n",
    "            if other_song not in user_liked_songs:  # Exclude already liked songs\n",
    "                similarity_score = adamic_adar_similarity(liked_song, other_song, graph)\n",
    "                \n",
    "                # Only add scores that are above the minimum threshold\n",
    "                if similarity_score > min_similarity:\n",
    "                    similarity_scores[other_song] += similarity_score\n",
    "    \n",
    "    # Sort and return the top N recommended songs\n",
    "    recommended_songs = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return recommended_songs[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82aaa53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Songs: [(b'SOQLGFP12A58A7800E', 3.083390054218504), (b'SODKPKO12A58A79DF7', 3.083390054218504), (b'SOZWTCR12A58A7BA31', 3.083390054218504), (b'SOXPJJT12AB01843F5', 3.083390054218504), (b'SOCTKZS12A58A7C5E6', 3.083390054218504)]\n"
     ]
    }
   ],
   "source": [
    "user_liked_songs = [b'SOMZWCG12A8C13C480', b'SOXVLOJ12AB0189215']\n",
    "recommended_songs = recommend_songs(user_liked_songs, graph)\n",
    "print(\"Recommended Songs:\", recommended_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b00fbe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'SOMZWCG12A8C13C480', b'SOXVLOJ12AB0189215']\n"
     ]
    }
   ],
   "source": [
    "print(user_liked_songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "506b6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song ID: SOQLGFP12A58A7800E | Similarity Score: 3.083390054218504\n",
      "Song ID: SODKPKO12A58A79DF7 | Similarity Score: 3.083390054218504\n",
      "Song ID: SOZWTCR12A58A7BA31 | Similarity Score: 3.083390054218504\n",
      "Song ID: SOXPJJT12AB01843F5 | Similarity Score: 3.083390054218504\n",
      "Song ID: SOCTKZS12A58A7C5E6 | Similarity Score: 3.5972883965882545\n",
      "Song ID: SOAPMKZ12A58A764B7 | Similarity Score: 3.083390054218504\n",
      "Song ID: SOIYNOF12AB0182141 | Similarity Score: 3.083390054218504\n"
     ]
    }
   ],
   "source": [
    "similarity_scores = {}\n",
    "\n",
    "# Create a list of all songs to avoid modifying the graph during iteration\n",
    "for liked_song, _ in recommended_songs:\n",
    "    for other_song in list(graph.keys()):  # Use list(graph.keys()) to avoid modifying the graph during iteration\n",
    "        if other_song not in user_liked_songs:  # Exclude already liked songs\n",
    "            similarity_score = adamic_adar_similarity(liked_song, other_song, graph)\n",
    "            similarity_scores[other_song] = similarity_score\n",
    "            \n",
    "            \n",
    "for song_id, score in similarity_scores.items():\n",
    "    if (score != 0):\n",
    "        print(f\"Song ID: {song_id.decode('utf-8')} | Similarity Score: {score}\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a762f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_recommended_songs(similarity_scores, top_n=3):\n",
    "    # Sort the similarity scores in descending order\n",
    "    sorted_scores = sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # Get the top N songs (top 3 by default)\n",
    "    top_songs = sorted_scores[:top_n]\n",
    "    \n",
    "    # Print the songs with their titles\n",
    "    for song_id, score in top_songs:\n",
    "        print_songs_from_bytehash(song_id)\n",
    "        print(f\"Similarity Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "83ca0d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song Title: b'Let Me'\n",
      "6\n",
      "Similarity Score: 3.5972883965882545\n",
      "Song Title: b'OAKtown'\n",
      "7\n",
      "Similarity Score: 3.083390054218504\n",
      "Song Title: b'I believe'\n",
      "9\n",
      "Similarity Score: 3.083390054218504\n"
     ]
    }
   ],
   "source": [
    "print_top_recommended_songs(similarity_scores, top_n=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
