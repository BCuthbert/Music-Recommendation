{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "629645f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import h5py\n",
    "import tables\n",
    "import matplotlib.pyplot as plt\n",
    "import hdf5_getters\n",
    "import glob\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0f0fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:/Users/mason/Downloads/millionsongsubset/MillionSongSubset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c392ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_data_from_file(file_path):\n",
    "    \"\"\" Extracts the required song data from a single HDF5 file. \"\"\"\n",
    "    try:\n",
    "        # Open the HDF5 file\n",
    "        h5_file = hdf5_getters.open_h5_file_read(file_path)\n",
    "        \n",
    "        # Extract the number of songs in the file\n",
    "        song_num = hdf5_getters.get_num_songs(h5_file)\n",
    "        \n",
    "        song_data_list = []  # List to store the data for all songs\n",
    "        \n",
    "        for i in range(song_num):\n",
    "            # Extract the required features for each song using the index\n",
    "            song_id = hdf5_getters.get_song_id(h5_file, i)\n",
    "            similar_artists = hdf5_getters.get_similar_artists(h5_file, i)\n",
    "            title = hdf5_getters.get_title(h5_file, i)\n",
    "            hotness = hdf5_getters.get_song_hotttnesss(h5_file, i)\n",
    "            duration = hdf5_getters.get_duration(h5_file, i)\n",
    "            tempo = hdf5_getters.get_tempo(h5_file, i)\n",
    "            track_id = hdf5_getters.get_track_id(h5_file, i)\n",
    "            artist = hdf5_getters.get_artist_id(h5_file, i)\n",
    "            \n",
    "            # Append the extracted data for the current song to the list\n",
    "            song_data = {\n",
    "                'song_id': song_id,\n",
    "                'similar_artists': similar_artists,\n",
    "                'title': title,\n",
    "                'hotness': hotness,\n",
    "                'duration': duration,\n",
    "                'tempo': tempo,\n",
    "                'track_id': track_id,\n",
    "                'artist': artist\n",
    "            }\n",
    "            song_data_list.append(song_data)\n",
    "        \n",
    "        # Close the file after extraction\n",
    "        h5_file.close()\n",
    "        \n",
    "        # Return the list of song data dictionaries\n",
    "        return song_data_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "def get_all_files(basedir,ext='.h5') :\n",
    "    \"\"\"\n",
    "    From a root directory, go through all subdirectories\n",
    "    and find all files with the given extension.\n",
    "    Return all absolute paths in a list.\n",
    "    \"\"\"\n",
    "    allfiles = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files :\n",
    "            allfiles.append( os.path.abspath(f) )\n",
    "    return allfiles\n",
    "\n",
    "def construct_dataframe_from_directory(directory):\n",
    "    \"\"\" Construct a DataFrame by iterating through all the HDF5 files in the given directory. \"\"\"\n",
    "    song_data = []\n",
    "    \n",
    "    songs = get_all_files(directory)  # Get the list of songs in the directory\n",
    "    \n",
    "    for song in songs:\n",
    "        song_data_from_file = get_song_data_from_file(song)\n",
    "        \n",
    "        if song_data_from_file:\n",
    "            # Flatten the list of song data into the main list\n",
    "            song_data.extend(song_data_from_file)\n",
    "    \n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(song_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913094d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = construct_dataframe_from_directory(base_path)\n",
    "print(d.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4207a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph_from_dataframe(df, min_songs_per_artist=2):\n",
    "    \"\"\" Construct a graph from the song data stored in a DataFrame, with a threshold for connections. \"\"\"\n",
    "    graph = defaultdict(set)  # Each song will have a set of connected songs\n",
    "    \n",
    "    # Iterate through each song in the dataframe\n",
    "    for _, row in df.iterrows():\n",
    "        song_id = row['song_id']\n",
    "        artist_id = row['artist']\n",
    "        \n",
    "        # Find other songs by the same artist\n",
    "        same_artist_songs = df[df['artist'] == artist_id]\n",
    "        \n",
    "        # Only create edges if there are at least 'min_songs_per_artist' songs by the same artist\n",
    "        if len(same_artist_songs) >= min_songs_per_artist:\n",
    "            for _, other_row in same_artist_songs.iterrows():\n",
    "                other_song_id = other_row['song_id']\n",
    "                \n",
    "                # Avoid connecting a song to itself\n",
    "                if song_id != other_song_id:\n",
    "                    graph[song_id].add(other_song_id)\n",
    "                    graph[other_song_id].add(song_id)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = construct_graph_from_dataframe(d, min_songs_per_artist=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247788ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamic_adar_similarity(song_id_1, song_id_2, graph):\n",
    "    common_neighbors = graph.get(song_id_1, set()).intersection(graph.get(song_id_2, set()))\n",
    "    \n",
    "    if not common_neighbors:\n",
    "        return 0\n",
    "    \n",
    "    score = 0\n",
    "    for neighbor in common_neighbors:\n",
    "        if neighbor in graph:\n",
    "            degree = len(graph[neighbor])\n",
    "            if degree > 1:\n",
    "                score += 1 / math.log(degree)\n",
    "    return score\n",
    "\n",
    "# Step 3: Generate recommendations for a user based on liked songs\n",
    "MIN_SIMILARITY_SCORE = 0.1\n",
    "\n",
    "def recommend_songs(user_liked_songs, graph, top_n=5, min_similarity=MIN_SIMILARITY_SCORE):\n",
    "    similarity_scores = defaultdict(float)\n",
    "    \n",
    "    for liked_song in user_liked_songs:\n",
    "        for other_song in list(graph.keys()):\n",
    "            if other_song not in user_liked_songs:  # Exclude already liked songs\n",
    "                similarity_score = adamic_adar_similarity(liked_song, other_song, graph)\n",
    "                \n",
    "                # Only add scores that are above the minimum threshold\n",
    "                if similarity_score > min_similarity:\n",
    "                    similarity_scores[other_song] += similarity_score\n",
    "    \n",
    "    # Sort and return the top N recommended songs\n",
    "    recommended_songs = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return recommended_songs[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aaa53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_liked_songs = [b'SOMZWCG12A8C13C480', b'SOXVLOJ12AB0189215']\n",
    "recommended_songs = recommend_songs(user_liked_songs, graph)\n",
    "print(\"Recommended Songs:\", recommended_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fbe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_liked_songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b6845",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = {}\n",
    "\n",
    "# Create a list of all songs to avoid modifying the graph during iteration\n",
    "for liked_song, _ in recommended_songs:\n",
    "    for other_song in list(graph.keys()):  # Use list(graph.keys()) to avoid modifying the graph during iteration\n",
    "        if other_song not in user_liked_songs:  # Exclude already liked songs\n",
    "            similarity_score = adamic_adar_similarity(liked_song, other_song, graph)\n",
    "            similarity_scores[other_song] = similarity_score\n",
    "            \n",
    "            \n",
    "for song_id, score in similarity_scores.items():\n",
    "    if (score != 0):\n",
    "        print(f\"Song ID: {song_id.decode('utf-8')} | Similarity Score: {score}\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_recommended_songs(similarity_scores, top_n=3):\n",
    "    # Sort the similarity scores in descending order\n",
    "    sorted_scores = sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # Get the top N songs (top 3 by default)\n",
    "    top_songs = sorted_scores[:top_n]\n",
    "    \n",
    "    # Print the songs with their titles\n",
    "    for song_id, score in top_songs:\n",
    "        print_songs_from_bytehash(song_id)\n",
    "        print(f\"Similarity Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b582040-908f-4a69-a878-5997dd5a1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded songs_metadata.csv to examine its structure\n",
    "file_path = 'C:/Users/mason/OneDrive/Desktop/graph_analysis/FINAL_PROJECT/PULL/Music-Recommendation/songs_metadata.csv'\n",
    "songs_metadata = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows and basic info of the dataset\n",
    "songs_metadata.info(), songs_metadata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94731bc8-7612-45ff-92fe-de0fe818a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded songs_metadata.csv to examine its structure\n",
    "file_path = 'C:/Users/mason/OneDrive/Desktop/graph_analysis/FINAL_PROJECT/PULL/Music-Recommendation/songs_metadata.csv'\n",
    "songs_metadata = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess similar_artists column (remove unwanted characters)\n",
    "songs_metadata['similar_artists'] = songs_metadata['similar_artists'].str.strip(\"[]\").str.replace(\"b'\", \"\").str.replace(\"'\", \"\")\n",
    "songs_metadata['similar_artists'] = songs_metadata['similar_artists'].str.split(\", \")\n",
    "\n",
    "# Initialize the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges\n",
    "for _, row in songs_metadata.iterrows():\n",
    "    song_id = row['song_id']\n",
    "    song_title = row['song_title']\n",
    "    similar_artists = row['similar_artists']\n",
    "\n",
    "    # Add the song node\n",
    "    G.add_node(song_id, label=song_title)\n",
    "\n",
    "    # Add edges to similar artists (if any)\n",
    "    if isinstance(similar_artists, list):\n",
    "        for similar in similar_artists:\n",
    "            similar = similar.strip()\n",
    "            if similar:  # Avoid empty entries\n",
    "                G.add_edge(song_id, similar)\n",
    "\n",
    "# Visualize the graph (sample 50 nodes for simplicity)\n",
    "plt.figure(figsize=(12, 8))\n",
    "subgraph = G.subgraph(list(G.nodes)[:2000])  # Sampling first 50 nodes\n",
    "pos = nx.spring_layout(subgraph, seed=42)\n",
    "nx.draw(subgraph, pos, with_labels=True, node_size=300, node_color='cyan', font_size=1, font_color=\"black\")\n",
    "plt.title(\"Song Recommendation Graph (Sampled)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_recommended_songs(similarity_scores, top_n=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
